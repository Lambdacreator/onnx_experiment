{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, opset=13)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx.save_model(onnx_model, \"simple_cnn_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import onnx.numpy_helper as numpy_helper\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def add(a, b):\n",
    "    return np.add(a, b)\n",
    "\n",
    "def matmul(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "def reshape(tensor, shape):\n",
    "    return np.reshape(tensor, shape)\n",
    "\n",
    "def conv(x, w, b=None, strides=(1, 1), pads=(0, 0, 0, 0)):\n",
    "    batch_size, in_channels, in_height, in_width = x.shape\n",
    "    out_channels, _, kernel_height, kernel_width = w.shape\n",
    "    stride_height, stride_width = strides\n",
    "    pad_height_begin, pad_width_begin, pad_height_end, pad_width_end = pads\n",
    "\n",
    "    out_height = (in_height + pad_height_begin + pad_height_end - kernel_height) // stride_height + 1\n",
    "    out_width = (in_width + pad_width_begin + pad_width_end - kernel_width) // stride_width + 1\n",
    "\n",
    "    y = np.zeros((batch_size, out_channels, out_height, out_width), dtype=np.float32)\n",
    "    \n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (pad_height_begin, pad_height_end), (pad_width_begin, pad_width_end)), mode='constant')\n",
    "    \n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride_height\n",
    "            h_end = h_start + kernel_height\n",
    "            w_start = j * stride_width\n",
    "            w_end = w_start + kernel_width\n",
    "            x_slice = x_padded[:, :, h_start:h_end, w_start:w_end]\n",
    "            for k in range(out_channels):\n",
    "                y[:, k, i, j] = np.sum(x_slice * w[k, :, :, :], axis=(1, 2, 3))\n",
    "                \n",
    "    if b is not None:\n",
    "        y += b.reshape(1, -1, 1, 1)\n",
    "        \n",
    "    return y\n",
    "\n",
    "def maxpool(x, kernel_shape, strides=(1, 1), pads=(0, 0, 0, 0)):\n",
    "    batch_size, in_channels, in_height, in_width = x.shape\n",
    "    kernel_height, kernel_width = kernel_shape\n",
    "    stride_height, stride_width = strides\n",
    "    pad_height_begin, pad_width_begin, pad_height_end, pad_width_end = pads\n",
    "\n",
    "    out_height = (in_height + pad_height_begin + pad_height_end - kernel_height) // stride_height + 1\n",
    "    out_width = (in_width + pad_width_begin + pad_width_end - kernel_width) // stride_width + 1\n",
    "\n",
    "    y = np.zeros((batch_size, in_channels, out_height, out_width), dtype=np.float32)\n",
    "\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (pad_height_begin, pad_height_end), (pad_width_begin, pad_width_end)), mode='constant')\n",
    "\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride_height\n",
    "            h_end = h_start + kernel_height\n",
    "            w_start = j * stride_width\n",
    "            w_end = w_start + kernel_width\n",
    "            x_slice = x_padded[:, :, h_start:h_end, w_start:w_end]\n",
    "            y[:, :, i, j] = np.max(x_slice, axis=(2, 3))\n",
    "\n",
    "    return y\n",
    "\n",
    "def transpose(x, perm):\n",
    "    return np.transpose(x, perm)\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "\n",
    "def shape(x):\n",
    "    return np.array(x.shape)\n",
    "\n",
    "def gather(x, indices, axis=0):\n",
    "    return np.take(x, indices, axis=axis)\n",
    "\n",
    "def cast(x, to):\n",
    "    onnx_to_numpy_dtype = {\n",
    "        1: np.float32,\n",
    "        2: np.uint8,\n",
    "        3: np.int8,\n",
    "        4: np.uint16,\n",
    "        5: np.int16,\n",
    "        6: np.int32,\n",
    "        7: np.int64,\n",
    "        8: np.str_,\n",
    "        9: np.bool_,\n",
    "        10: np.float16,\n",
    "        11: np.double,\n",
    "        12: np.uint32,\n",
    "        13: np.uint64,\n",
    "        14: np.complex64,\n",
    "        15: np.complex128\n",
    "    }\n",
    "    return x.astype(onnx_to_numpy_dtype[to])\n",
    "\n",
    "def reduceprod(x, axis=None, keepdims=False):\n",
    "    if axis is not None:\n",
    "        if isinstance(axis, (list, tuple)):\n",
    "            for ax in axis:\n",
    "                x = np.prod(x, axis=ax, keepdims=keepdims)\n",
    "            return x\n",
    "        else:\n",
    "            return np.prod(x, axis=axis, keepdims=keepdims)\n",
    "    else:\n",
    "        return np.prod(x, keepdims=keepdims)\n",
    "\n",
    "def unsqueeze(x, axes):\n",
    "    for axis in sorted(axes):\n",
    "        x = np.expand_dims(x, axis)\n",
    "    return x\n",
    "\n",
    "def concat(*tensors, axis=0):\n",
    "    tensors = [np.atleast_1d(tensor) for tensor in tensors]  # Ensure all tensors are at least 1-dimensional\n",
    "    return np.concatenate(tensors, axis=axis)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gemm(a, b, c=None, alpha=1.0, beta=1.0, trans_a=False, trans_b=False):\n",
    "    if trans_a:\n",
    "        a = a.T\n",
    "    if trans_b:\n",
    "        b = b.T\n",
    "    y = alpha * np.dot(a, b)\n",
    "    if c is not None:\n",
    "        y += beta * c\n",
    "    return y\n",
    "\n",
    "# Map ONNX operator names to functions\n",
    "operator_map = {\n",
    "    'Relu': relu,\n",
    "    'Add': add,\n",
    "    'MatMul': matmul,\n",
    "    'Reshape': reshape,\n",
    "    'Conv': conv,\n",
    "    'MaxPool': maxpool,\n",
    "    'Transpose': transpose,\n",
    "    'Softmax': softmax,\n",
    "    'Shape': shape,\n",
    "    'Gather': gather,\n",
    "    'Cast': cast,\n",
    "    'ReduceProd': reduceprod,\n",
    "    'Unsqueeze': unsqueeze,\n",
    "    'Concat': concat,\n",
    "    'Sigmoid': sigmoid,\n",
    "    'Gemm': gemm,\n",
    "    # Add more operators\n",
    "}\n",
    "\n",
    "def execute_node(node, inputs):\n",
    "    input_tensors = [inputs[input_name] for input_name in node.input]\n",
    "    print(f\"Executing {node.op_type} with inputs: {[t.shape for t in input_tensors]}\")\n",
    "    \n",
    "    if node.op_type == 'Reshape':\n",
    "        shape_tensor = input_tensors[1]\n",
    "        if isinstance(shape_tensor, list):\n",
    "            shape_tensor = np.array(shape_tensor)\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], shape_tensor)\n",
    "    elif node.op_type == 'Conv':\n",
    "        attrs = {attr.name: attr.ints for attr in node.attribute}\n",
    "        strides = tuple(attrs.get('strides', [1, 1]))\n",
    "        pads = tuple(attrs.get('pads', [0, 0, 0, 0]))\n",
    "        b = input_tensors[2] if len(input_tensors) > 2 else None\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], input_tensors[1], b, strides, pads)\n",
    "    elif node.op_type == 'MaxPool':\n",
    "        attrs = {attr.name: attr.ints for attr in node.attribute}\n",
    "        kernel_shape = attrs.get('kernel_shape', [2, 2])\n",
    "        strides = tuple(attrs.get('strides', [1, 1]))\n",
    "        pads = tuple(attrs.get('pads', [0, 0, 0, 0]))\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], kernel_shape, strides, pads)\n",
    "    elif node.op_type == 'Transpose':\n",
    "        perm = node.attribute[0].ints if node.attribute else []\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], perm)\n",
    "    elif node.op_type == 'Gather':\n",
    "        indices = input_tensors[1]\n",
    "        axis = node.attribute[0].i if node.attribute else 0\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], indices, axis)\n",
    "    elif node.op_type == 'Cast':\n",
    "        to = node.attribute[0].i  # The data type to cast to (ONNX data type enum)\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], to)\n",
    "    elif node.op_type == 'ReduceProd':\n",
    "        axis = node.attribute[0].ints if node.attribute else None\n",
    "        if axis is not None:\n",
    "            axis = list(axis)  # Convert to list if it's a RepeatedScalarContainer\n",
    "        keepdims = node.attribute[1].i if len(node.attribute) > 1 else False\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], axis, keepdims)\n",
    "    elif node.op_type == 'Unsqueeze':\n",
    "        axes = node.attribute[0].ints if node.attribute else []\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], axes)\n",
    "    elif node.op_type == 'Concat':\n",
    "        axis = node.attribute[0].i if node.attribute else 0\n",
    "        output_tensors = operator_map[node.op_type](*input_tensors, axis=axis)\n",
    "    elif node.op_type == 'Sigmoid':\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0])\n",
    "    elif node.op_type == 'Gemm':\n",
    "        attrs = {attr.name: attr for attr in node.attribute}\n",
    "        alpha = attrs['alpha'].f if 'alpha' in attrs else 1.0\n",
    "        beta = attrs['beta'].f if 'beta' in attrs else 1.0\n",
    "        trans_a = attrs['transA'].i if 'transA' in attrs else 0\n",
    "        trans_b = attrs['transB'].i if 'transB' in attrs else 0\n",
    "        c = input_tensors[2] if len(input_tensors) > 2 else None\n",
    "        output_tensors = operator_map[node.op_type](input_tensors[0], input_tensors[1], c, alpha, beta, trans_a, trans_b)\n",
    "    else:\n",
    "        output_tensors = operator_map[node.op_type](*input_tensors)\n",
    "\n",
    "    if not isinstance(output_tensors, tuple):\n",
    "        output_tensors = (output_tensors,)\n",
    "\n",
    "    for output_name, output_tensor in zip(node.output, output_tensors):\n",
    "        inputs[output_name] = output_tensor\n",
    "    print(f\"Produced output for {node.op_type}: {output_tensors[0].shape}\")\n",
    "    \n",
    "\n",
    "def execute_graph(graph, input_data):\n",
    "    inputs = {}\n",
    "\n",
    "    # Use provided input data\n",
    "    for input_tensor in graph.input:\n",
    "        input_name = input_tensor.name\n",
    "        inputs[input_name] = input_data\n",
    "        print(f\"Loaded input {input_name} with shape {input_data.shape}\")\n",
    "\n",
    "    # Initialize tensors for constants (initializers)\n",
    "    for initializer in graph.initializer:\n",
    "        tensor = numpy_helper.to_array(initializer)\n",
    "        inputs[initializer.name] = tensor\n",
    "        print(f\"Initialized tensor {initializer.name} with shape {tensor.shape}\")\n",
    "\n",
    "    # Execute nodes\n",
    "    for node in graph.node:\n",
    "        execute_node(node, inputs)\n",
    "\n",
    "    # Extract outputs\n",
    "    outputs = {output.name: inputs[output.name] for output in graph.output}\n",
    "    return outputs\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = 'simple_cnn_model.onnx'\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "# Get the graph from the model\n",
    "graph = model.graph\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_test = np.expand_dims(x_test, axis=-1)  # Add channel dimension\n",
    "\n",
    "# Select a test sample\n",
    "input_data = x_test[0:1]  # Selecting the first sample and keeping it as a batch\n",
    "\n",
    "# Execute the graph with the input data\n",
    "outputs = execute_graph(graph, input_data)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
